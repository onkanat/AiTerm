{
  "model_configurations": {
    "production_ready": {
      "ollama_local": {
        "primary": {
          "model": "codellama:7b-instruct",
          "parameters": {
            "temperature": 0.05,
            "top_p": 0.9,
            "repeat_penalty": 1.1,
            "num_ctx": 4096,
            "stop": ["\\n", "```", "```json"]
          },
          "use_case": "Terminal commands, code generation",
          "memory_requirement": "8GB",
          "response_time": "fast",
          "accuracy": "high"
        },
        "secondary": {
          "model": "llama3.1:8b-instruct-q4_0",
          "parameters": {
            "temperature": 0.1,
            "top_p": 0.8,
            "repeat_penalty": 1.05,
            "num_ctx": 8192,
            "stop": ["\\n"]
          },
          "use_case": "Complex reasoning, explanation mode",
          "memory_requirement": "8GB",
          "response_time": "medium",
          "accuracy": "very_high"
        },
        "security_focused": {
          "model": "gemma2:9b-instruct-q4_0",
          "parameters": {
            "temperature": 0.1,
            "top_p": 0.85,
            "repeat_penalty": 1.05,
            "num_ctx": 4096,
            "stop": ["\\n"]
          },
          "use_case": "Security-critical environments",
          "memory_requirement": "10GB",
          "response_time": "medium",
          "accuracy": "high",
          "security_score": "excellent"
        }
      },
      "cloud_api": {
        "cost_effective": {
          "provider": "openai",
          "model": "gpt-4o-mini",
          "parameters": {
            "temperature": 0.05,
            "max_tokens": 200,
            "frequency_penalty": 0.1,
            "presence_penalty": 0.0,
            "stop": ["\\n"]
          },
          "cost_per_1m_tokens": 0.15,
          "response_time": "very_fast",
          "accuracy": "excellent"
        },
        "premium": {
          "provider": "anthropic",
          "model": "claude-3-5-haiku-20241022",
          "parameters": {
            "temperature": 0.05,
            "max_tokens": 200,
            "stop_sequences": ["\\n"]
          },
          "cost_per_1m_tokens": 0.25,
          "response_time": "very_fast",
          "accuracy": "excellent",
          "security_score": "outstanding"
        },
        "balanced": {
          "provider": "google",
          "model": "gemini-1.5-flash",
          "parameters": {
            "temperature": 0.1,
            "max_output_tokens": 200,
            "stop_sequences": ["\\n"]
          },
          "cost_per_1m_tokens": 0.075,
          "response_time": "fast",
          "accuracy": "high",
          "free_tier": true
        }
      }
    },
    "experimental": {
      "bleeding_edge": {
        "model": "qwen2.5-coder:7b-instruct",
        "parameters": {
          "temperature": 0.05,
          "top_p": 0.9,
          "repeat_penalty": 1.1,
          "num_ctx": 4096
        },
        "specialty": "Code and terminal commands",
        "status": "testing"
      },
      "multimodal": {
        "model": "llava:7b",
        "parameters": {
          "temperature": 0.1,
          "top_p": 0.8
        },
        "specialty": "Image-based command understanding",
        "status": "research"
      }
    }
  },
  "prompt_templates": {
    "v2_1_optimized": {
      "turkish": {
        "base": "Sen uzman bir Linux/macOS terminal asistanısın. SADECE geçerli JSON formatında yanıt ver.",
        "rules": [
          "SADECE tek satırda geçerli JSON döndür, başka hiçbir metin ekleme",
          "Özel karakterler için JSON escaping kullan (\\\", \\n, \\t)",
          "Kullanıcı dili otomatik tespit et ve aynı dilde yanıt ver"
        ],
        "modes": {
          "command": "{\\\"command\\\": \\\"shell_komutu\\\"}",
          "explanation": "{\\\"explanation\\\": \\\"türkçe_açıklama\\\"}"
        },
        "security": "Tehlikeli isteklerde: {\\\"command\\\": \\\"DANGER\\\"} veya {\\\"explanation\\\": \\\"DANGER\\\"}"
      },
      "english": {
        "base": "You are an expert Linux/macOS terminal assistant. Respond ONLY with valid JSON format.",
        "rules": [
          "Return ONLY valid JSON on single line, no other text",
          "Use proper JSON escaping for special characters (\\\", \\n, \\t)",
          "Auto-detect user language and respond in same language"
        ],
        "modes": {
          "command": "{\\\"command\\\": \\\"shell_command\\\"}",
          "explanation": "{\\\"explanation\\\": \\\"english_explanation\\\"}"
        },
        "security": "For dangerous requests return: {\\\"command\\\": \\\"DANGER\\\"} or {\\\"explanation\\\": \\\"DANGER\\\"}"
      }
    },
    "security_enhanced": {
      "base": "You are a security-aware terminal assistant. Always prioritize user safety.",
      "security_patterns": [
        "System destruction: rm -rf /, dd commands",
        "Privilege escalation: sudo su, unauthorized access",
        "Network attacks: malicious downloads, port scanning",
        "Data exfiltration: unauthorized data access",
        "Resource exhaustion: fork bombs, infinite loops"
      ],
      "escalation_prompt": "If unsure about command safety, always choose DANGER response."
    }
  },
  "performance_tuning": {
    "response_optimization": {
      "cache_strategy": {
        "enable": true,
        "ttl_seconds": 3600,
        "max_entries": 1000,
        "cache_dangerous_responses": false
      },
      "timeout_settings": {
        "ollama_local": 30,
        "openai_api": 15,
        "anthropic_api": 20,
        "google_api": 10
      },
      "retry_logic": {
        "max_retries": 2,
        "backoff_multiplier": 1.5,
        "retry_on_json_error": true
      }
    },
    "quality_assurance": {
      "response_validation": {
        "require_json": true,
        "require_mode_field": true,
        "max_response_length": 500,
        "min_response_length": 10
      },
      "security_scoring": {
        "enable": true,
        "danger_threshold": 0.7,
        "auto_reject_high_risk": true
      }
    }
  },
  "usage_scenarios": {
    "beginner_user": {
      "recommended_model": "gpt-4o-mini",
      "security_level": "high",
      "explanation_mode_default": true,
      "features": ["safety_warnings", "command_explanations", "alternative_suggestions"]
    },
    "power_user": {
      "recommended_model": "codellama:7b-instruct",
      "security_level": "medium",
      "command_mode_default": true,
      "features": ["fast_execution", "advanced_commands", "scripting_support"]
    },
    "enterprise": {
      "recommended_model": "claude-3-5-haiku",
      "security_level": "maximum",
      "audit_logging": true,
      "features": ["compliance_checks", "admin_approval", "detailed_logging"]
    },
    "developer": {
      "recommended_model": "qwen2.5-coder:7b",
      "security_level": "medium",
      "code_focus": true,
      "features": ["git_integration", "development_tools", "project_context"]
    }
  },
  "benchmark_results": {
    "test_scenarios": {
      "command_generation": {
        "codellama:7b": {"accuracy": 92, "speed": 8.5, "security": 85},
        "llama3.1:8b": {"accuracy": 89, "speed": 7.2, "security": 88},
        "gpt-4o-mini": {"accuracy": 96, "speed": 9.8, "security": 91},
        "claude-3-5-haiku": {"accuracy": 94, "speed": 9.5, "security": 97}
      },
      "security_detection": {
        "codellama:7b": {"detection_rate": 78, "false_positives": 5},
        "llama3.1:8b": {"detection_rate": 82, "false_positives": 8},
        "gpt-4o-mini": {"detection_rate": 89, "false_positives": 3},
        "claude-3-5-haiku": {"detection_rate": 95, "false_positives": 2}
      },
      "multilingual_support": {
        "turkish_accuracy": {
          "codellama:7b": 85,
          "llama3.1:8b": 88,
          "gpt-4o-mini": 94,
          "claude-3-5-haiku": 92
        },
        "english_accuracy": {
          "codellama:7b": 93,
          "llama3.1:8b": 91,
          "gpt-4o-mini": 97,
          "claude-3-5-haiku": 96
        }
      }
    }
  },
  "deployment_recommendations": {
    "quick_start": {
      "model": "codellama:7b-instruct",
      "config": "production_ready.ollama_local.primary",
      "setup_command": "ollama pull codellama:7b-instruct",
      "estimated_setup_time": "10 minutes"
    },
    "production": {
      "primary": "gpt-4o-mini",
      "fallback": "codellama:7b-instruct",
      "monitoring": true,
      "rate_limiting": true,
      "cost_optimization": true
    },
    "high_security": {
      "model": "claude-3-5-haiku",
      "additional_validation": true,
      "human_approval_required": true,
      "audit_all_commands": true
    }
  }
}